{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77a5701-bbc4-4f02-be3b-84c8abecceb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "from harness_pipeline import HarnessPipeline\n",
    "from datalogger import DataLogger\n",
    "from seed_data_mappers import lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3a7516-eac1-4720-9df7-c4b7975d30a1",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e6d747-7b07-47cd-a5a1-1f4274e1cdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_files(directory):\n",
    "    # Count files in the given directory\n",
    "    file_count = 0\n",
    "    try:\n",
    "        # List all entries in the directory\n",
    "        entries = os.listdir(directory)\n",
    "        # Iterate through the entries and count only the files\n",
    "        for entry in entries:\n",
    "            entry_path = os.path.join(directory, entry)\n",
    "            # Check if it's a file\n",
    "            if os.path.isfile(entry_path):\n",
    "                file_count += 1\n",
    "    except Exception as e:\n",
    "        print(f\"Error accessing directory: {e}\")\n",
    "        return -1  # Return -1 or some other error indicator if desired\n",
    "\n",
    "    return file_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dc9d76-84e3-4ef1-8c82-d9d26163c7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(directory):\n",
    "    ret = []\n",
    "    entries = os.listdir(directory)\n",
    "    # Iterate through the entries and print only the files (ignore directories)\n",
    "    for entry in entries:\n",
    "        entry_path = os.path.join(directory, entry)\n",
    "        # Check if it's a file and not a directory\n",
    "        if os.path.isfile(entry_path):\n",
    "            matches = re.findall(r\"atheris_(.*?)_Initial\", entry_path)\n",
    "            ret.append( (entry_path, matches[0]) )\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac2084c-f4e9-413c-8ea0-4fcc312e3a82",
   "metadata": {},
   "source": [
    "# Experiment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6764b8c6-68cd-4734-8ee8-17dd07d9e06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_only = True # Set to true to get results for only the seeds without mutation\n",
    "save_path = './results/'\n",
    "corpora_path = './corpora/'\n",
    "directory_path = './drivers/'\n",
    "\n",
    "# Corpora to test with, must be present in the 'corpora_path'\n",
    "tests = [ \n",
    "          ('gpt-3.5-turbo', 1.0, 'simple'),\n",
    "          ('gpt-3.5-turbo', 1.0, 'complex'),\n",
    "          ('gpt-3.5-turbo', 1.0, 'merge'),\n",
    "          ('gpt-4-turbo-preview', 1.0, 'simple'),\n",
    "          ('gpt-4-turbo-preview', 1.0, 'complex'),\n",
    "          ('gpt-4-turbo-preview', 1.0, 'merge'),\n",
    "          ('claude-3-opus-20240229', 1.0, 'simple'),\n",
    "          ('claude-3-opus-20240229', 1.0, 'complex'),\n",
    "          ('claude-3-opus-20240229', 1.0, 'merge'),\n",
    "          ('claude-instant-1.2', 1.0, 'simple'),\n",
    "          ('claude-instant-1.2', 1.0, 'complex'),\n",
    "          ('claude-instant-1.2', 1.0, 'merge'),\n",
    "          ('gemini-1.0-pro', 1.0, 'simple'),\n",
    "          ('gemini-1.0-pro', 1.0, 'complex'),\n",
    "          ('gemini-1.0-pro', 1.0, 'merge')   \n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb967ab-1dfd-41c6-8d59-9cadc5409065",
   "metadata": {},
   "source": [
    "# Run Experiment\n",
    "\n",
    "Step through each driver, load the appropriate corpora and capture coverage measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b72c1c-b026-4a06-a6d5-84c9aa2fa94f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for filepath, name in get_files(directory_path):\n",
    "    print(f\"\\nTesting: {name}\\n\")\n",
    "    for model_version, temperature, corpus_name in tests:\n",
    "        post_fix = \"\"\n",
    "        if corpus_only: post_fix = \"_only\"\n",
    "        results_file = f\"{save_path}{name}_{model_version}_{temperature}_{corpus_name}{post_fix}\"\n",
    "        num_profiling_runs = 100_000\n",
    "        harness_runs = 5\n",
    "                \n",
    "        corpus_location = f\"{corpora_path}{name}/{model_version}/{temperature}/{corpus_name}_corpus\"\n",
    "        \n",
    "        # Skip if results already exist to support restarting\n",
    "        if os.path.exists(results_file + \".parquet\"):\n",
    "            print(  \"Skipping\\n\")\n",
    "            continue\n",
    "        \n",
    "        if corpus_name == \"none\": corpus_location = None\n",
    "        if corpus_only:\n",
    "            if corpus_location is None: continue\n",
    "            harness_runs = 1\n",
    "            num_profiling_runs = count_files(corpus_location)\n",
    "            print(f\"({num_profiling_runs}) {corpus_location}\\n\")\n",
    "\n",
    "        # Just using the testing functionality directly\n",
    "        harness_maker = HarnessPipeline(lookup[name], num_profiling_runs=num_profiling_runs, harness_runs=harness_runs,\n",
    "                                        model_version=model_version, temperature=temperature, use_docs=False)\n",
    "        \n",
    "        avg, diff = harness_maker.test_harness(filepath, corpus_location=corpus_location, finish_df=False)\n",
    "        print(f\"  Runs: {harness_runs}, Steps: {num_profiling_runs}\\n\")\n",
    "        print(f\"  Model: {model_version}, Temp: {temperature}, Corpus: {corpus_name}\\n\")\n",
    "        print(f\"  Avgs: {avg:0.2f}, Diff: {diff}\\n\\n\")\n",
    "        \n",
    "        DataLogger.create_dataframe(results_file)\n",
    "print(f\"\\n>> Done <<\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amira",
   "language": "python",
   "name": "amira"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
